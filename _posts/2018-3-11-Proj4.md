---
layout: post
title: Project 4 - Joke Analysis with NLP and Recommender Systems Using Unsupervised Machine Learning
---

## Problem to be Solved
I have always been interested in what makes people laugh. It seems the phrase "sense of humor" means something completely different to each person. I was interested in investigating the construction of jokes, and determining if there are patterns to the type of humor individuals enjoy. To do this, I obtained a dataset that contained 25,000 people's responses to 100 different jokes. Each person rated the "funny-ness" of the joke on a scale from -10 to 10. After analysis, I could finally answer the age old question: "Whats so funny?"

## Business Applications
Aside from being an interesting and entertaining topic of investigation, this research has applications for businesses as well. For example, companies with AI bots could use this research to inject (tasteful) humor into their applications such as Siri and Alexa. This would make the AI applications feel more friendly and relatable. Additionally, marketing teams could use this information to create customer humor demographics to direct more targeted ads toward their clients. Humor is a tool people use to create a relaxed and fun atmosphere, and businesses can use that to their advantage.

## Analysis Strategy
I decided to use a 2-sided approach to understand this data:
- Analyze the text
- Analyze the ratings

To analyze the text, I used tools from the NLP toolkit such as count vectorizer and TF-IDF vectorizer to perform sentiment analysis and word similarity. 

## K-Means Clustering
K-Means Clustering is a tool for Unsupervised Machine Learning. It assigns randomly-located centroids to the data, and then calculates the distance from the centroid to each nearby point. After it has learned where each point is, the location of the centroid is updated. I used this algorithm to determine how many clusters fit in my data. I checked the algorithm against many different cluster sizes, and used the sillouette score to determine how well each number of clusters fit the data. The number of clusters with the highest sillouette score and lowest SSE (sum of squared error) was k=11. 

## Latent Dirichlet Allocation Topic Modeling
I used my discoveries from K-Means Clustering to educate my guesses for LDA Topic Modeling. When I ran the topic modeling algorithm, I got jokes split up into discrete topics:
- Married life
- Jokes about women
- Jokes about education
- Jokes about infidelity
- “Screw in a lightbulb”
- “Good News/Bad News”
- Exclamations, nonsense words and words out of context
- Non-US Nationalities
- Family Drama
- Jokes about religion
- Children’s lives/children’s point of view

## Building a Joke Recommender System
I built a recommender system using Scikit-Surprise, a relatively straighforward recommender package. The algorithm uses collaborative filtering technique to predict ratings of users. For my recommender, I created a brand new blank user. Then, as the new user starts rating jokes, their humor profile gets more and more fleshed out, which leads to better recommendations as time goes by. 

## Overall Conclusions
My analysis states that jokes (more specifically, jokes from this dataset) can be classified into 11 distinct categories based on topic. Additionally, my recommender can predict a good joke for any user. These insights can allow marketing teams and AI developers to make their products and advertising campaigns more friendly and relatable in the future. 
