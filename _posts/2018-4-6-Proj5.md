---
layout: post
title: Project 5 - Detecting Exoplanets with NASA
---

## Problem to be Solved:
Each of the stars in the night sky has the potential for multiple planets orbiting around it. These extra-solar planets are called "exoplanets". It is outrageously difficult to detect these planets because of the vast distances between stars, and planets, unlike stars, do not create their own light. In fact, the best way to detect exoplanets is actually through a *lack* of light. As a planet completes its orbit around the host star, there is a non-zero probability that the planet's orbit will cross the disc of the star. If you were able to witness the total solar eclipse in August 2017, you'll know that when some object crosses in front of its star (ex, the Moon), the light from the star (ex, our Sun) becomes significantly dimmer. This detection technique is called the "Transit Method". Using this technique NASA's Kepler Spacecraft has been able to detect 3,708 exoplanets to date. The Kepler mission ran from 2009-2013, and looked at 150,000 main Sequence stars. Now, NASA's TESS (Transiting Exoplanet Survey Satellite) will use the same technique to discover exoplanets at much higher resolution!

## Partnering with NASA
I reached out to NASA when I started working on this project. I knew that the format of the data would probably be in a NASA-specific format, and I needed tools and advice about how to handle it. I emailed the team at Kepler Guest Observer Office, and was surprised when they responded back in mere hours. Dr Christina Hedges and Dr Michael Gully-Santiago were incredibly helpful in getting me set up with access to the Kepler Database, and showed me a package they created called "lightkurve" which specifically deals with transit data from Kepler. Perfect! 

## Data Collection
The raw data that streams directly from Kepler is in the form of .fits images. "Fits" stands for Flux In Time Series. This data is not a typical "image", it has flux data imbedded in it. Flux is a measure of the energy coming from a specific point at a given moment, which is exactly the same as measuring the "brightness" of a star. 

I chose to use data from week 1 of the Kepler Mission. I used Lightkurve to download all the flux images from 9000 stars. Then, I cross checked the data with the NASA Exoplanet Archive, which lists the status of each star, whether there is a confirmed exoplanet or not. As an interesting hiccup in the data collection, the NASAEA only lists data for stars that contain "confirmed" exoplanets or "false positive". None of the stars in my dataset are blank, boring confirmed negatives. This certainly makes my project more challenging and interesting. I combined the information from NASAEA and the raw flux data to obtain my dataset for testing.  

## Data Cleaning and Feature Engineering
I then ran the data through the lightkurve package. I defined a function called TFsinglestarpipe which takes in the KeplerID supplied by NASAEA, and returns a numpy array that contains 1626 values, ie.e. the flux measurement at each hour for that particular star. I pushed the data through a rather convoluted pipeline that looks something like this:
```
def TFsinglestarpipe(kepid):
    try:
        tpf = KeplerTargetPixelFile.from_archive(kepid, quarter=1)  
        lc = tpf.to_lightcurve(aperture_mask=tpf.pipeline_mask)
        flat, trend = lc.flatten(window_length=301, return_trend=True)
        df = flat.to_pandas()
    
        df = df.drop(columns = ['time', 
                        'flux_err', 
                        'quality', 
                        'centroid_row', 
                        'centroid_col',
                        'KeplerID'], axis=1)
    
        df = df.reset_index(drop=True)
        df.index.names = [kepid]
    
        flux = df['flux']
        array = list(flux)
        return array
    except:
        return None
```
I first uploaded the star's Kepler target pixel file from the MAST archive (an in-house, open-source NASA archive) based on the KeplerID. A Target Pixel File is very similar to typical astronomical FITS image, TPFs can be thought of as stacks of images, with one image for every timestamp the telescope took data. I then converted the Target Pixel File to a Light Curve, which creates a graphical representation of the flux over time, plotting flux on the y axis and time on the x axis. From there, I negated any noise trends, converted the flux values into a pandas dataframe, and converted the pandas dataframe to a numpy array.  

I then created my training and test sets manually, creating a list of lists (flux data per star).
```
xtrain = []
ytrain = []

for i in tqdm(range(7000)):
    if TFsinglestarpipe(starlist[i]):
        xtrain.append(TFsinglestarpipe(starlist[i]))
        ytrain.append(dy['Disposition'][i])
    else:
        pass

X_train = np.array(xtrain)
Y_train = np.array(ytrain)
```
In the end, the train set contained records of 5725 stars, and the test set had 2160.
Now on to feature engineering!

## Feature Engineering
I now had huge dataframes filled with data in time series. I created new parameters based on the flux data. I created Min, Max, range, and duration of exoplanet transit. These features were simple, but I hoped they contained all the data necessary to determine which stars have orbiting exoplanets.

## First Model: Neural Networks using Keras with Tensorflow
Immediately before I started working on this project, Google Brain released a blog post about how they designed a neural network that could detect exoplanets from Kepler's data. You can read the blog post [here](https://research.googleblog.com/2018/03/open-sourcing-hunt-for-exoplanets.html). I read this post and was inspired to take on the problem. Thinking, naively, that I knew exactly what I needed to do to create a fully functional exoplanet detection model from scratch. 

Little did I know, the Researchers at Google had actually re-engineered certain Tensorflow packages and commands. By the time they had a working model, their code was barely recognizable to an untrained eye like mine. My inital dream of creating a model from scratch was looking more and more unattainable. 

Never to be deterred, I pressed on and slowly started to chip away at the huge mountain of knowledge needed to create a TensorFlow neural network. Luckily TensorFlow has great documentation, and there are plenty of people who have created online resources. 

For the first Neural Network model I made, I inputted the raw flux vectors. These values appeared as a seemingly endless string of numbers. However, my model was complete spaghetti, and treated the data like random gibberish. From this, I learned that Neural Networks are not the silver bullet from the future, and that models are only as good as the data.

## Second Model: Nested Categorical Modeling
Then, I used the feature engineered data set and inputted into a categorical model. The models I decided to use were: Random Forest, Decision Tree, and Logistic Regression. These models each predicted whether each star was "True" (this star has exoplanets), or "False" (this star likely does not have any orbiting exoplanets). From there, I created a completely new dataset based on the results from my categorical model. I cropped out the stars my model specified as exoplanet-negative, and fed this smaller (postive only) dataset to another categorical model. I tuned the first model to be very sensative, and avoid False Negatives as much as possible. The theory behind my nested-model strategy was that the first model would cut out all the False Negatives, and my second model would cut out all the False Positives. I had 3 new datasets from each of the three first-stage categorical models, and I fed each of them into another set of categorical models: Random Forest, Decision Tree, and Logistic Regression. These results were not very descriptive of my dataset, and did not score very well in terms of accuracy and precision. 

## Third Model: Simple Categorical Modeling
As my third trial, I inputed the original feature engineered dataset into simple categorical models. I tried using 3 models: Random Forest, Decision tree, and Logisitic Regression. After completing many complex data analysis processes, I was throughly shocked that the simplest model scored the best! Decision trees and Random forest models both performed very well! In fact, I could limit the amount of training data down from 3 years to just 1 year of data, and the models still performed with 78% accuracy. 

## Conclusions
Often, the simplest models are the most powerful. I was able to predict with 78% accuracy if a star has exoplanets or not with only 1 years' worth of data. 
